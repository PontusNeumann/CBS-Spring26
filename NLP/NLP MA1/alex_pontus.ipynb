{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mandatory Assignment 01\n",
    "## Natural Language Processing and Text Analytics (KAN-CDSCO1002U)\n",
    "\n",
    "**Alex & Pontus**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 1: Mandatory Question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following two sentences are ambiguous -- that is, they each have two (or more) different readings. For each sentence, explain the different readings:\n",
    "\n",
    "**1. The girl attacked the boy with the book.**\n",
    "\n",
    "reading 1: the girl \n",
    "**2. We decided to leave on Saturday.**\n",
    "\n",
    "*Your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are the following sentences ambiguous? If the sentence is ambiguous, explain the different readings. If not, explain why not.\n",
    "\n",
    "**3. I saw a man with a briefcase.**\n",
    "\n",
    "*Your answer here*\n",
    "\n",
    "**4. I saw the planet with a telescope.**\n",
    "\n",
    "*Your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try the above sentences (3 and 4) in this parse tree generator: https://huggingface.co/spaces/nanom/syntactic_tree\n",
    "\n",
    "Compare the dependency structures for both of them. Explain the differences in the link to the preposition \"with\" in 3 vs. 4.\n",
    "\n",
    "*Your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 2: Select any one question to answer\n",
    "\n",
    "*(Choose either Option A or Option B below)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option A: Linguistic Analysis of a Text Corpus Using spaCy\n",
    "\n",
    "There is an uploaded text corpus named `sample.xlsx`. Conduct a linguistic analysis using Part-of-Speech (POS) tagging and Named Entity Recognition (NER) in spaCy library only on the \"SOS Tweet/SOS Message\" column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 1: Prepare the Corpus\n",
    "Pre-process the corpus data by removing stopwords, removing extra spaces, converting all text to lowercase, or apply any other text normalization techniques that you think is relevant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 1: Prepare the Corpus\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 2: POS Tagging and NER\n",
    "Apply POS tagging to the entire corpus to analyze the distribution of different parts of speech. Use NER to identify and categorize named entities within the text such as name, date, locations etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 2: POS Tagging and NER\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 3: Analysis\n",
    "Determine the most common POS tags and discuss what this reveals about the structure of the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 3: Analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 4: Short Report (1-2 pages)\n",
    "Summarize your findings in a brief report, including any interesting patterns or insights gained from the POS and NER analysis.\n",
    "\n",
    "*Your report here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Option B: Next Word Prediction System Based on N-gram Model\n",
    "\n",
    "In this part you are going to work with a language model using Natural Language Toolkit (NLTK). Create an n-gram (either for n=3 or n=4) language model and use it to predict the next word."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 1: Prepare the Corpus\n",
    "Choose a text corpus of your choice from Gutenberg as your training corpus. As long as the corpus is of significant size (a few megabytes of text), it should be fine. For example you can choose `austen-emma.txt`. Pre-process the corpus by removing stopwords, removing extra spaces, converting all text to lowercase, or apply any other text normalization techniques that you think is relevant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 1: Prepare the Corpus\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 2: Build the Language Model\n",
    "From the preprocessed text, generate n-grams. You might use NLTK's `ngrams` function to do this. Calculate the counts of each unique n-gram in the corpus. Calculate the conditional probability of each word following a given (n-1) word sequence based on the n-gram counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 2: Build the Language Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 3: Word Prediction Mechanism\n",
    "Create a function that takes a sequence of (n-1) words as input and returns the most probable next word based on your n-gram model. The function should handle cases where the input sequence has not been seen in the training data (you may choose a simple strategy such as returning a random word from the corpus or use any smoothing technique)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 3: Word Prediction Mechanism\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 4: Evaluation\n",
    "Test your model with 10 input sequences of (n-1) from within and outside the corpus. Assess the model's prediction ability by checking if the predicted next words are sensible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 4: Evaluation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 5: Short Report (1-2 pages)\n",
    "Summarize your findings in a brief report.\n",
    "\n",
    "**Hint:** Note that the probabilities of n-grams will have very low values and in order to deal with multiplication of low probabilities and thereby arithmetic underflow, you can use logarithmic (log) values for probabilities.\n",
    "\n",
    "*Your report here*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
